{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind gradient boosting is that we start off with any random model, usually being an unoptimized tree, and then, based off its predictions, optimize the bias. Since most models rely on $\\hat{y}+bias$ to get the real prediction, we're pretty much just approximating our function, but through the bias term rather than coefficients.\n",
    "\n",
    "#### Intuitive description of the algorithm\n",
    "- The starting model, based on which we are going to optimize the bias, could be anything, even the mean value across all predictions. By plugging $X$ we get initial predictions $\\hat{y}$;\n",
    "- We calculate residuals $e=y-\\hat{y}$. Now we build a \"weak learner\" for the bias term. For example, it could be a decision tree that predicts the bias. Not that in the regression problem if there are more than one value left in the leaf node, we take the average to yeild the prediction. For more generalization we plug $\\eta$ as a learning rate parameter to the predicted residuals;\n",
    "- We calculate new predictions based on $\\hat{y}+\\eta\\times e_1$ and then repeat the process until we reach $M$ iterations or a desired quality\n",
    "\n",
    "#### Mathematically strictier description\n",
    "- Initially we want to find such an arbitrary function $\\hat{f}(x)$ that minimizes $y\\approx\\hat{f}(x)$. That means that $\\hat{f}(x)=argmin_{f(x)}L(y,f(x))$, where $L(y,f)$ is some **differentiable** loss function\n",
    "- Since the range of possible functions approximating $f(x)$ is infinite, we limit the problem to a family of functions $f(x,\\theta), \\theta\\in R^d$ (for example a decision tree) and transform the problem to finding best $\\theta$ instead of some \"function\": $\\hat{\\theta}=argmin_{\\theta}E_{x,y}[L(y,f(x,\\theta))]$, where $E$ - expected value or mean. \n",
    "    > **Improtant reminder** is that just like in every other NN we get best parameters by applying gradient descend with some multiplication by $\\eta\\in(0,1]$, i.e. each parameter actually consists of a negative sum of losses with preadded initial value of the parameter. Therefore, for better intuition we can rewrite the optimization problem as $\\hat{\\theta}=\\sum^N_{i=1}L(y_i,f(x_i,\\hat{\\theta}))$\n",
    "- Right now it seems that GBMs are nothing more but a fancier way to describe regular linear models. To elevate confusion it is important to say that GBMs approximate a function as a sum of incremental improvements, **each being a function**, i.e. $\\hat{f}(x)=\\sum_{i=0}^M\\hat{f_i}(x)$, where $\\hat{f}(x)$ is limited by some function family $\\hat{f}(x)=h(x,\\theta)$. Moreover on every step of finding another function (from now on we will also refer to them as \"models\") we also need to select an optimal $\\rho\\in R$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Loss(object):\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return NotImplementedError()\n",
    "\n",
    "    def gradient(self, y, y_pred):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def acc(self, y, y_pred):\n",
    "        return 0\n",
    "\n",
    "class SquareLoss(Loss):\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def loss(self, y, y_pred):\n",
    "        return 0.5 * np.power((y - y_pred), 2)\n",
    "\n",
    "    def gradient(self, y, y_pred):\n",
    "        return -(y - y_pred)\n",
    "\n",
    "class CrossEntropy(Loss):\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def loss(self, y, p):\n",
    "        # Avoid division by zero\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return - y * np.log(p) - (1 - y) * np.log(1 - p)\n",
    "\n",
    "    def acc(self, y, p):\n",
    "        return accuracy_score(np.argmax(y, axis=1), np.argmax(p, axis=1))\n",
    "\n",
    "    def gradient(self, y, p):\n",
    "        # Avoid division by zero\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return - (y / p) + (1 - y) / (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "class gbm():\n",
    "    \n",
    "    def  __init__(self, eta, m, min_samples, min_impurity, \n",
    "                  max_depth, is_reg) -> None:\n",
    "        self.eta = eta\n",
    "        self.m = m\n",
    "        self.min_samples = min_samples\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "        self.is_reg = is_reg\n",
    "\n",
    "        self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
